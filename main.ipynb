{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong> Computational Photography <strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### <strong>Some of the Professor's Research:</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The profesor created a algorithm to turn an image into a simple 3-D scene. \n",
    "- Other research focused on turning images into 3-D scenes/ models. \n",
    "- Inserting objects into images, and making those pasted objects look like they were in the original photograph. \n",
    "- Generating videos based off of text input (comic strips).\n",
    "- Creating 3D, AR models of construction sites (Reconstruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <Strong> Some Context on Computational Photography </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Depictions of people and scenes have changed a lot over the last few thousands of years (from abstract, iconography - to realism)\n",
    "    - shift to perspective, real-life scenes\n",
    "<img src=\"./Arnolfini_Portrait.png\" alt=\"Arnolfini's Portrait and Mirror\">\n",
    "- Then there was the camera: first used to help artists draw realistic scenes (the Lens Based Camera Obscura)\n",
    "    - hard to learn to draw things as they are, vs how we perceive them\n",
    "<img src=\"./Daguerre.png\" alt=\"Daguerre\">\n",
    "- But are photos really realistic?\n",
    "    - photos can be staged (like the Iraqi photo, and touched up photos in magazines.)\n",
    "    - this is where computer graphics come in. \n",
    "        - Model the 3D model of the scene\n",
    "        - use a physics engine to render from any viewpoint\n",
    "        - hard to do well\n",
    "        - sometimes looks too shiny, too real\n",
    "        - people are hard to do, pores, wrinkles, glow\n",
    "- The realism spectrum\n",
    "    - Computer Graphics:\n",
    "        - easy to create new worlds\n",
    "        - easy to manipulate objects/ viewpoints\n",
    "        - very hard to make look realistic\n",
    "    - Photography\n",
    "        - instantly realistic\n",
    "        - easy to aquire\n",
    "        - very hard to manipulate objects/ viewpoints\n",
    "- Computational photography = the best of both worlds\n",
    "    - How can I use computational techniques to capture light in new ways?\n",
    "    - How can I use computational techniques to breathe new light into the photograph?\n",
    "    - How can I use computational techniques to synthesize and organize photo collections?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### <strong>Course Objectives</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "1. You will have new abilities for visual creation\n",
    "2. You will get a foundation for computer vision\n",
    "3. You will better appreciate your own visual ability \n",
    "\n",
    "<img src=\"./Thinking.png\" alt=\"Daguerre\">\n",
    "\n",
    "4. You will have fun doing cool stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Course Projects</strong>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hybrid images\n",
    "    - Creating an image that has signal from 2 different images (different interpretation depending on the size of the image)\n",
    "2. Image quilting for texture synthesis and transfer\n",
    "    - being able to create texture in images (face on toast)\n",
    "3. Poisson editing\n",
    "    - Picture of swimming pool + picture of a bear = blended in bear into a swimming pool\n",
    "4. Image-based lighting\n",
    "    - capturing light with mirrored ball\n",
    "5. Video alignment, sitching, editing\n",
    "    - panoramic video insertion and deletion\n",
    "6. Do something cool\n",
    "    - should be about the same scale as the previous projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Pixel and Image Filters</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image formation\n",
    "    - digital camera records light into CCD (converts photons of light into electrons)\n",
    "    - measuring the total number of photos that reach each cell\n",
    "    - the original signal could be nice and continuous (curved), but is converted to discrete and blocky for the camera\n",
    "    - this is why elements of images can be pixelated and noisy\n",
    "    - Raster image\n",
    "        - matrix representation of an image\n",
    "        - one value per pixel of the image\n",
    "    - Perception of intensity\n",
    "        - humans can be tricked by our own visual system (checkerboard shadow example)\n",
    "    - Digital Color Images\n",
    "        - using filters, CCD's can record color based on intensity \n",
    "        - all images are just three colors with different intensities (RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in python..\n",
    "\n",
    "import cv2\n",
    "\n",
    "im = cv2.imread(filename)\n",
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # orders channels as RGB\n",
    "im = im / 255 # values range from 0 to 1\n",
    "\n",
    "# RGB image im is a H x W x 3 matrix (numpy.ndarray)\n",
    "\n",
    "im[0,0,0] # top left pixel value in R-channel\n",
    "im[y, x, c] # y + 1 pixels down, x + 1 pixels to the right in the cth channel\n",
    "im[H-1, W-1, 2] # bottom right pixel in the B channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Filtering\n",
    "\n",
    "- is the compute function of local neighborhood at each position\n",
    "- Really important\n",
    "    - enhance images\n",
    "        - denoise, resize, increase contrast, etc\n",
    "    - extract information from images\n",
    "        - texture, edges, distinctive points, etc\n",
    "    - detect patterns \n",
    "        - template matching\n",
    "- box filter\n",
    "    - looks like a box in 2D plot\n",
    "    - a 3x3 matrix filter applied to an image means you take each 3x3 part of the image, and get the dot product of of each segment\n",
    "- what does a filter do?\n",
    "    - it sort of blurs out the image\n",
    "    - smoothes\n",
    "    - reduces contrast\n",
    "    - convolution (?)\n",
    "    - answer: takes the average of each window\n",
    "-  You have to get the dot product of the filter and the segment of the image you are looking at. The segment of the image matches the filter image in terms of size.\n",
    "- The resulting image is the same size as the original image, as the affected pixel during each round of the filtering operation is just the one in the middle. We handle the edges of the photo differently. \n",
    "- This process is called the filtering operation\n",
    "- What different filters do\n",
    "    - zero matrix with a 1 in the center?\n",
    "        - does nothing, as every pixel gets replaced by itself. \n",
    "        - called the identity filter\n",
    "    - A zero matrix (3x3) with a single one at position 23?\n",
    "        - shifted to the left\n",
    "    - Doubling the image (zero matrxi with 2 in the center), and then subtracting a box filter?\n",
    "        - this is a sharpening filter\n",
    "        - if you subtract a blurred image from a sharp image, you just get the sharper image\n",
    "        - making the differences in pixel intensities STRONGER\n",
    "    - Edge filter\n",
    "        - [1, 0, -1\n",
    "           2, 0, -2\n",
    "           1, 0, -1]\n",
    "        - gets the absolute value of an image\n",
    "        - sum of pixels from the left and subtracting the pixels from the right\n",
    "        - turning this filter horizontal makes a Sobel filter\n",
    "- How can we synthesize motion blur?\n",
    "    - shift the image by multiple positions and then average it out\n",
    "    - How is this done with a filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "im_fn = './Thinking.png'\n",
    "\n",
    "im = cv2.imread(im_fn)\n",
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)/255 # convert to grayscale for now\n",
    "\n",
    "theta = 0\n",
    "len = 15\n",
    "mid = (len-1)/2\n",
    "\n",
    "fil = np.zeros((len,len))\n",
    "print(fil)\n",
    "\n",
    "fil[:, int(mid)] = 1/len\n",
    "R = cv2.getRotationMatrix2D((mid, mid),theta,1)\n",
    "fil = cv2.warpAffine(fil, R, (len,len))\n",
    "\n",
    "im_fil = cv2.filter2D(im, -1, fil)\n",
    "\n",
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(3,1,figsize=(50,50))\n",
    "axes[0] = imshow(im,cmap='gray')\n",
    "axes[1] = imshow(im,cmap='gray')\n",
    "axes[2] = imshow(im,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation vs Convolution\n",
    "\n",
    "- different terms for filtering. \n",
    "- sometimes used interchangably\n",
    "- strong relationship between them though\n",
    "- correlation\n",
    "    - when you take a window over the image, you multiply corresponding elements of the window with the kernel (filter matrix)\n",
    "- convolution\n",
    "    - same as correlation, but you rotate the kernel first by 180 degrees\n",
    "    - calculated using fast fourier transforms\n",
    "- if you can do correlation, you can also do convolution\n",
    "- if you have a symetric kernel, the output will be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key properties of linear filters\n",
    "\n",
    "- linearity\n",
    "    - if you filter the sum of two signals, that is the same as filtering each separately and adding those responses together\n",
    "- shift invariance\n",
    "    - same behavior regardless of pixel location\n",
    "    - filter(shift(f)) = shift(filter(f))\n",
    "    - any linear shift invariant operator can also be represented as a convolution\n",
    "- cummutative\n",
    "    - a * b = b * a\n",
    "    - conceptually not difference between filter and signal (image)\n",
    "    - I could also filter my blur kernel with my image, and I get the same result. This is unlike matrices of linear algebra\n",
    "- associative \n",
    "    - a * (b * c) = (a * b) * c\n",
    "    - often apply several filters one after another\n",
    "    - this is equivalent to applying one filter\n",
    "- distributes over addition \n",
    "    - a * (b + c) = (a * b) + (a * c)\n",
    "- scalars factor out\n",
    "- identity filter is a filter with a 1 in the center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important filter: Gaussian\n",
    "\n",
    "- 4 representations as depicted in the lecture\n",
    "- effective smoother without edgey artifacts (compared to box filter)\n",
    "- remove \"high frequency\" components from the image (low pass filter)\n",
    "    - images become more smooth\n",
    "- if you convolve a gaussian with another gaussian you get another gaussian. (Ring a bell from stats? Normal distribution + normal distribution = normal distribution)\n",
    "    - convolving twice with a gaussian kernal of width sigma is the same as convolving once with a kernel of width sigma * radical 2. \n",
    "- separable\n",
    "    - you can divide it into a product of two 1-D Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separability \n",
    "\n",
    "To summarize what the professor said here, separability just describes the fact that we can split our filter into smaller filters. The example given was splitting a 3x3 filter into the two 1x3 and 3x1 filters that could be multiplied to produce it. Using these two to convolve on the image instead of the larger 3x3 matrix is much faster for larger matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practical matters\n",
    "\n",
    "- How big should a filter be?\n",
    "    - values at edges should be near zero\n",
    "    - rule of thumb for Gaussian: set kernel half-width to >= 3*sigma (since Gaussian is not discrete and can't be zero)\n",
    "    - this just says that if the standard deviation of the pixel values is 1, then we want the size of the filter to be 7 by 7 (3 sigma is 3, so we want 3 on one side, 3 on the other, 1 value in the middle)\n",
    "    - too small of a size on the Gaussian results in what is essentially the box filter\n",
    "- What about near the edge?\n",
    "    - the filter window falls off the edge of the image\n",
    "    - need to extrapolate - aka making the image larger such that our filter can fit.\n",
    "    - methods (all can be done in Python)\n",
    "        - clipping (black filter around the whole image)\n",
    "        - wrap around \n",
    "        - copy edge\n",
    "        - reflect across edge (DEFAULT)\n",
    "    - What is the size of the output?\n",
    "        - full (response is the size of original image plus what we extrapolated)\n",
    "        - same (response is the size of original image) (DEFAULT)\n",
    "        - valid (original image does not get padded at all, just record response where filter fits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application Representing Texture\n",
    "\n",
    "- regular or stochastic patterns caused by bumps, grooves, and/ or markings\n",
    "- How can we represent texture?\n",
    "    - computre respones of blobs and edges at various orientations and scales\n",
    "    - filter bank = set of filters\n",
    "    - we can apply multiple filters to an image and measure the responses of each one to see how much of an impact that filter made on the image\n",
    "    - the result is a vector to describe the image\n",
    "        - this tells us something about the texture of the image\n",
    "        - for example, what would it mean if we saw there was a high response to verticle filters in an image, low responses to horizontal filters, and low responses to blob filters (blob meaning what it sounds like, organic circular looking patterns)?\n",
    "            - probably means we have an image with a vertical looking texture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid Images (Project 1)\n",
    "\n",
    "- a way of combining two images so that you get a different perception of the image depending on your distance to the image\n",
    "- Gaussian filtered image (smooth image) + laplacian filtered image (detail image) = hybrid image\n",
    "- far away and small = blurred image\n",
    "- close and large = detail image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "- images are a matrix of numbers\n",
    "- linear fitering is the dot product at each window position of the image with the filter (kernel)\n",
    "- be aware of details (size of filter, extrapolation, cropping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
